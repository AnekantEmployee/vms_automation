import re
import time
import pandas as pd
from dotenv import load_dotenv
from typing import List, Dict, Any
from langchain_core.prompts import PromptTemplate
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.output_parsers import StrOutputParser

# Load environment variables
load_dotenv()


def get_gemini_model():
    """Initialize Gemini 2.5 Flash model"""
    try:
        return ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            temperature=0.1,
            max_tokens=150,
        )
    except Exception as e:
        print(f"Error initializing Gemini model: {e}")
        return None


def extract_column_data(observations_df: pd.DataFrame) -> Dict[str, List[str]]:
    """
    Extract top 5 unique values from each column
    """
    print("📊 Processing top 5 values from each column...")

    column_data = {}

    for column in observations_df.columns:
        # Get top 5 unique non-empty values from the column
        values = [
            str(val).strip()
            for val in observations_df[column].unique()  # Get unique values first
            if pd.notna(val) and str(val).strip()
        ][
            :5
        ]  # Then take first 5
        if values:
            column_data[column] = values

    print(f"✓ Extracted data from {len(column_data)} columns (top 5 values each)")
    return column_data


def analyze_column_vulnerabilities(
    column_name: str, column_values: List[str], model
) -> List[Dict[str, str]]:
    """
    Analyze a column's top 5 values to identify specific vulnerabilities
    Returns only unique vulnerabilities per column
    """
    vulnerabilities = []
    seen_vulnerabilities = set()

    # Combine the top 5 values for analysis
    sample_values = " | ".join(column_values)

    # First try pattern matching on the column name and sample values
    vulnerability = pattern_match_vulnerabilities(f"{column_name}: {sample_values}")

    # If no pattern match, use AI analysis
    if not vulnerability and model:
        vulnerability = analyze_observation_vulnerabilities(
            f"Column '{column_name}' contains these values: {sample_values}", model
        )

    # Add valid vulnerabilities
    if (
        vulnerability
        and vulnerability
        not in ["AI Model Unavailable", "Analysis Failed", "No Clear Vulnerability"]
        and vulnerability not in seen_vulnerabilities
    ):
        seen_vulnerabilities.add(vulnerability)
        vulnerabilities.append(
            {
                "Column": column_name,
                "Vulnerability": vulnerability,
            }
        )

    return vulnerabilities


def create_vulnerability_analysis_from_columns(
    observations_df: pd.DataFrame,
) -> List[Dict[str, Any]]:
    """
    Analyze Observations sheet columns to extract unique vulnerabilities
    """
    print("🎯 Analyzing Observations sheet columns for unique vulnerabilities...")

    model = get_gemini_model()
    column_data = extract_column_data(observations_df)
    vulnerability_findings = []
    global_seen_vulnerabilities = set()  # Track vulnerabilities across all columns

    for column_name, column_values in column_data.items():
        print(f"🔍 Analyzing column: {column_name}")

        try:
            column_vulns = analyze_column_vulnerabilities(
                column_name, column_values, model
            )

            # Only add vulnerabilities we haven't seen before
            for vuln in column_vulns:
                if vuln["Vulnerability"] not in global_seen_vulnerabilities:
                    vulnerability_findings.append(vuln)
                    global_seen_vulnerabilities.add(vuln["Vulnerability"])
                    print(f"  ⚠️ Found new vulnerability: {vuln['Vulnerability']}")
                else:
                    print(
                        f"  ➡️ Skipping duplicate vulnerability: {vuln['Vulnerability']}"
                    )

            time.sleep(1.5)  # Rate limiting

        except Exception as e:
            print(f"❌ Error analyzing column {column_name}: {e}")
            continue

    print(
        f"🎯 Completed analysis: {len(vulnerability_findings)} unique vulnerabilities identified"
    )
    return vulnerability_findings


def analyze_observation_vulnerabilities(observation_data: str, model) -> str:
    """
    Analyze observation data to identify specific vulnerabilities
    """
    if not model:
        return "AI Model Unavailable"

    # Enhanced prompt for observations analysis
    prompt_template = PromptTemplate(
        input_variables=["observation_data"],
        template="""
        You are analyzing security observation data from a penetration test or vulnerability scan.
        
        Observation Data: {observation_data}
        
        Based on this data, identify the PRIMARY security vulnerability. Be specific and use these exact terms when applicable:

        For authentication issues:
        - "Username Enumeration Vulnerability"
        - "Weak Password Policy"
        - "Missing Multi-Factor Authentication"
        
        For protocol/encryption issues:
        - "Weak Protocols Enabled (SSHv1, TLS 1.0)"
        - "Insecure HTTP Protocol Usage"
        - "Weak SSL/TLS Configuration"
        
        For headers/cookies:
        - "Missing Security Headers (CSP, X-Frame-Options)"
        - "Missing HttpOnly Cookie Attribute"
        - "Missing Secure Cookie Flag"
        
        For file handling:
        - "Missing File Upload Validation"
        - "Unrestricted File Upload Vulnerability"
        
        For input handling:
        - "Improper Input Validation"
        - "Missing Input Sanitization"
        
        For libraries/frameworks:
        - "Vulnerable Bootstrap Version (X.Y.Z)"
        - "Vulnerable jQuery Version (X.Y.Z)"
        
        For hashing:
        - "Weak Hashing Algorithm (MD5)"
        - "Weak Hashing Algorithm (SHA1)"
        
        Respond with ONLY the specific vulnerability name (maximum 5 words).
        If no clear vulnerability, respond with "No Clear Vulnerability".
        """,
    )

    try:
        chain = prompt_template | model | StrOutputParser()

        # Limit observation data length
        if len(observation_data) > 400:
            observation_data = observation_data[:400] + "..."

        result = chain.invoke({"observation_data": observation_data})

        # Clean the response
        vulnerability = result.strip()

        # Remove explanations, keep only vulnerability name
        if "\n" in vulnerability:
            vulnerability = vulnerability.split("\n")[0]

        # Ensure it's not too long
        words = vulnerability.split()
        if len(words) > 6:
            vulnerability = " ".join(words[:6])

        return vulnerability

    except Exception as e:
        print(f"Error in vulnerability analysis: {e}")
        return "Analysis Failed"


def pattern_match_vulnerabilities(observation_text: str) -> str:
    """
    Pattern matching for common vulnerability indicators in observations
    Returns more specific vulnerability names
    """
    text_lower = observation_text.lower()

    # Username enumeration
    if re.search(r"\b(username|user|login|account)\b", text_lower):
        return "Username Enumeration Vulnerability"

    # Subdomain enumeration
    if re.search(r"\b\w+\.\w+\.\w+\b", observation_text) and "subdomain" in text_lower:
        return "Subdomain Enumeration Exposure"

    # Open ports - more specific
    if re.search(r":\d{1,5}\b", observation_text):
        if re.search(r":22\b", observation_text):
            return "SSH Port Open (Weak Protocol)"
        elif re.search(r":23\b", observation_text):
            return "Telnet Port Open (Weak Protocol)"
        elif re.search(r":80\b", observation_text):
            return "HTTP Port Open (Missing Encryption)"
        elif re.search(r":443\b", observation_text):
            return "HTTPS Port Open"
        else:
            return "Unnecessary Port Open"

    # Directory listing
    if re.search(r"/[\w\-]+/", observation_text):
        return "Directory Listing Enabled"

    # Hashing algorithms
    if re.search(r"\b[a-f0-9]{32}\b", text_lower):
        return "Weak Hashing Algorithm (MD5)"
    if re.search(r"\b[a-f0-9]{40}\b", text_lower):
        return "Weak Hashing Algorithm (SHA1)"
    if re.search(r"\b[a-f0-9]{64}\b", text_lower):
        return "Weak Hashing Algorithm (SHA-256)"

    # Protocol issues
    if "http://" in text_lower:
        return "Insecure HTTP Protocol Enabled"
    if any(term in text_lower for term in ["ssl", "tls"]):
        return "Weak SSL/TLS Configuration"

    # Security headers
    if any(term in text_lower for term in ["header", "x-frame", "csp", "hsts"]):
        if "missing" in text_lower or "not present" in text_lower:
            return "Missing Security Headers"
        return "Insecure Security Headers Configuration"

    # Cookie attributes
    if any(term in text_lower for term in ["cookie", "httponly", "secure"]):
        if "httponly" not in text_lower:
            return "Missing HttpOnly Cookie Attribute"
        if "secure" not in text_lower:
            return "Missing Secure Cookie Flag"
        return "Insecure Cookie Configuration"

    # Vulnerable libraries
    if any(term in text_lower for term in ["jquery", "bootstrap"]):
        return "Vulnerable JavaScript Library Version"

    # File upload
    if any(term in text_lower for term in ["upload", "file"]):
        if "validation" not in text_lower or "filter" not in text_lower:
            return "Missing File Upload Validation"

    # Input validation
    if any(term in text_lower for term in ["input", "validation"]):
        if "missing" in text_lower or "not validated" in text_lower:
            return "Improper Input Validation"

    # IP addresses
    if re.search(r"\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b", observation_text):
        return "Sensitive IP Address Disclosure"

    return None


def create_findings_node(state):
    """
    Process Observations sheet columns to create unique vulnerability findings
    """
    try:
        print("🔍 Processing Observations sheet columns for unique vulnerabilities...")

        if not state.get("success", False):
            raise Exception("Previous node failed or no data available")

        observations_df = state["observations_df"]

        if observations_df is None or observations_df.empty:
            raise Exception("Observations DataFrame is empty or None")

        print(
            f"📊 Found observations data with {len(observations_df)} rows and {len(observations_df.columns)} columns"
        )

        # Analyze columns for vulnerabilities
        vulnerability_findings = create_vulnerability_analysis_from_columns(
            observations_df
        )

        if vulnerability_findings:
            findings_df = pd.DataFrame(vulnerability_findings)
            findings_df = findings_df.sort_values("Vulnerability", ascending=True)
            print(
                f"✓ Created findings sheet with {len(findings_df)} unique vulnerability entries"
            )
        else:
            findings_df = pd.DataFrame(
                {
                    "Result": ["No specific vulnerabilities identified"],
                    "Analysis_Summary": [
                        f"Processed {len(observations_df.columns)} columns (top 5 values each)"
                    ],
                    "Note": ["Consider manual review of the observations data"],
                }
            )
            print("✓ No vulnerabilities identified in columns")

        return {
            "success": True,
            "error": None,
            "findings_df": findings_df,
            "total_vulnerabilities": len(vulnerability_findings),
            "total_columns_processed": len(observations_df.columns),
        }

    except Exception as e:
        print(f"✗ Error in create_findings_node: {e}")
        return {
            "success": False,
            "error": str(e),
            "findings_df": pd.DataFrame(
                {"Error": [f"Failed to process observations: {str(e)}"]}
            ),
        }
